<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">




<title></title>

<link href="https://fonts.googleapis.com/css?family=Roboto+Slab:100,300,400,700" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300,300i,400,400i,700,700i" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i" rel="stylesheet"/>

<script src="site_libs/header-attrs-2.6/header-attrs.js"></script>
<link href="site_libs/ipsum-0.1.0/ipsum.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/default.css"
      type="text/css" />
<script src="site_libs/highlight.js"></script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>
<div class="container">

<h1></h1>


<div id="toc">
<ul>
<li><a href="#simulating-pi">Simulating pi</a></li>
<li><a href="#submitting-jobs-to-slurm">Submitting jobs to Slurm</a></li>
<li><a href="#jobs-with-the-slurmr-package">Jobs with the slurmR package</a></li>
</ul>
</div>

<div id="simulating-pi" class="section level2">
<h2>Simulating pi</h2>
<p>This is the same old example that lots of people (including me) have been using to ilustrate parallel computing with R. The example is very simple, we want to approximate pi by doing some Monte Carlo simulations.</p>
<p>We know that the area of a circle is <span class="math inline">\(A = \pi r^2\)</span>, which is equivalent to say <span class="math inline">\(\pi = A/r^2\)</span>, so, if we can approximate the Area of a circle, then we can approximate <span class="math inline">\(\pi\)</span>. How do we do this?</p>
<p>Using montecarlo experiments, we have that the probability that a random point <span class="math inline">\(x\)</span> falls within the unit circle can be approximated using the following formula</p>
<p><span class="math display">\[
\hat p = \frac{1}{n}\sum_i \mathbf{1}(x \in \mbox{Circle})
\]</span></p>
<p>This approximation, <span class="math inline">\(\hat p\)</span>, multiplied by the area of the escribed square, which has an area equal to <span class="math inline">\((2\times r)^2\)</span>, thus, we can finally write</p>
<p><span class="math display">\[
\hat \pi = \hat p \times (2\times r)^2 / r^2 = 4 \hat p
\]</span></p>
</div>
<div id="submitting-jobs-to-slurm" class="section level2">
<h2>Submitting jobs to Slurm</h2>
<p>The main way that we will be working is submitting jobs using the <code>sbatch</code> function. This function takes as a main argument a bash file with the program to execute. In the case of R, a regular bash file looks something like this:</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=sapply
#SBATCH --time=01:00:00

module load usc r
Rscript --vanilla 01-sapply.R</code></pre>
<p>This file has three components:</p>
<ul>
<li><p>The Slurm flags <code>#SBATCH</code>.</p></li>
<li><p>Loading R <code>module load usc</code> and <code>module load r</code>.</p></li>
<li><p>Executing the R script.</p></li>
</ul>
<p>To submit a job the to queue, we need to enter the following:</p>
<pre class="bash"><code>sbatch 01-sapply.slurm</code></pre>
<p>The following examples have two files, a bash script and a R script to be called by Slurm.</p>
<div id="case-1-single-job-single-core-job" class="section level3">
<h3>Case 1: Single job, single core job</h3>
<p>The most basic way is submitting a job using the <a href=""><code>sbatch</code></a> command. Im this case you need to have 2 files: (1) An R script, and (2) a bash script. e.g.</p>
<p>The contents of the R script (<a href="01-sapply.R" target="_blank">01-sapply.R</a>) are:</p>
<pre><code># Model parameters
nsims &lt;- 1e3
n     &lt;- 1e4

# Function to simulate pi
simpi &lt;- function(i) {
  
  p &lt;- matrix(runif(n*2, -1, 1), ncol = 2)
  mean(sqrt(rowSums(p^2)) &lt;= 1) * 4
  
}

# Approximation
set.seed(12322)
ans &lt;- sapply(1:nsims, simpi)

saveRDS(ans, &quot;01-sapply.rds&quot;)</code></pre>
<p>The contents of the bashfile (<a href="01-sapply.slurm" target="_blank">01-sapply.slurm</a>) are:</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=sapply
#SBATCH --time=01:00:00

module load usc r
Rscript --vanilla 01-sapply.R</code></pre>
</div>
<div id="case-2-single-job-multicore-job" class="section level3">
<h3>Case 2: Single job, multicore job</h3>
<p>Now, imagine that we would like to use more than one processor for this job, using something like the <code>parallel::mclapply</code> function from the parallel package. Then, besides of adapting the code, we need to tell Slurm that we are using more than one core per-task, as the following example:</p>
<p>R script (<a href="02-mclapply.R" target="_blank">02-mclapply.R</a>):</p>
<pre><code># Model parameters
nsims  &lt;- 1e3
n      &lt;- 1e4
ncores &lt;- 4L

# Function to simulate pi
simpi &lt;- function(i) {
  
  p &lt;- matrix(runif(n*2, -1, 1), ncol = 2)
  mean(sqrt(rowSums(p^2)) &lt;= 1) * 4
  
}

# Approximation
set.seed(12322)
ans &lt;- parallel::mclapply(1:nsims, simpi, mc.cores = ncores)
ans &lt;- unlist(ans)

saveRDS(ans, &quot;02-mclpply.rds&quot;)</code></pre>
<p>Bashfile (<a href="02-mclapply.slurm" target="_blank">02-mclapply.slurm</a>):</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=mclapply
#SBATCH --time=01:00:00
#SBATCH --cpus-per-task=4

module load usc r
Rscript --vanilla 02-mclapply.R</code></pre>
</div>
</div>
<div id="jobs-with-the-slurmr-package" class="section level2">
<h2>Jobs with the slurmR package</h2>
<div id="case-3-single-job-multinode-job" class="section level3">
<h3>Case 3: Single job, multinode job</h3>
<p>In this case, there is no simple way to submit a multinodal job to Slurm… unless you use the <a href="https://github.com/USCbiostats/slurmR"><strong>slurmR</strong></a> package (see installation instructions <a href="https://github.com/USCbiostats/slurmR#installation"><strong>here</strong></a>)</p>
<p>Once you have the slurmR package in your system, you can proceed as follow</p>
<p>R script (<a href="03-parsapply-slurmr.R" target="_blank">03-parsapply-slurmr.R</a>):</p>
<pre><code># Model parameters
nsims  &lt;- 1e3
n      &lt;- 1e4
ncores &lt;- 4L

# Function to simulate pi
simpi &lt;- function(i) {
  
  p &lt;- matrix(runif(n*2, -1, 1), ncol = 2)
  mean(sqrt(rowSums(p^2)) &lt;= 1) * 4
  
}

# Setting up slurmR
library(slurmR) # This also loads the parallel package

# Making the cluster, and exporting the variables
cl &lt;- makeSlurmCluster(ncores)

# Approximation
clusterExport(cl, c(&quot;n&quot;, &quot;simpi&quot;))
ans &lt;- parSapply(cl, 1:nsims, simpi)

# Closing connection
stopCluster(cl)

saveRDS(ans, &quot;03-parsapply-slurmr.rds&quot;)</code></pre>
<p>Bashfile (<a href="03-parsapply-slurmr.slurm" target="_blank">03-parsapply-slurmr.slurm</a>):</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=parsapply
#SBATCH --time=01:00:00

module load usc r
Rscript --vanilla 03-parsapply-slurmr.R</code></pre>
</div>
<div id="case-4-multi-job-singlemulti-core" class="section level3">
<h3>Case 4: Multi job, single/multi-core</h3>
<p>Another way to submit jobs is using <a href="https://slurm.schedmd.com/job_array.html"><strong>job arrays</strong></a>. A job array is essentially a job that is repreated <code>njobs</code> times with the same configuration. The main difference between replicates is what you do with the <code>SLURM_ARRAY_TASK_ID</code> environment variable. This variable is defined within each replicate and can be used to make the “subjob” depending on that.</p>
<p>Here is a quick example using R</p>
<pre class="r"><code>ID &lt;- Sys.getenv(&quot;SLURM_ARRAY_TASK_ID&quot;)
if (ID == 1) {
  ...[do this]...
} else if (ID == 2) {
  ...[do that]...
}</code></pre>
<p>The <code>slurmR</code> R package makes submitting job arrays easy. Again, with the simulation of pi, we can do it in the following way:</p>
<p>R script (<a href="04-slurm_sapply.R" target="_blank">04-slurm_sapply.R</a>):</p>
<pre><code># Model parameters
nsims  &lt;- 1e3
n      &lt;- 1e4
# ncores &lt;- 4L
njobs  &lt;- 4L

# Function to simulate pi
simpi &lt;- function(i, n.) {
  
  p &lt;- matrix(runif(n.*2, -1, 1), ncol = 2)
  mean(sqrt(rowSums(p^2)) &lt;= 1) * 4
  
}

# Setting up slurmR
library(slurmR) # This also loads the parallel package

# Approximation
ans &lt;- Slurm_sapply(
  1:nsims, simpi,
  n.       = n,
  njobs    = njobs,
  plan     = &quot;collect&quot;,
  tmp_path = &quot;/staging/ggv&quot; # This is where all temp files will be exported
  )

saveRDS(ans, &quot;04-slurm_sapply.rds&quot;)</code></pre>
<p>Bashfile (<a href="04-slurm_sapply.slurm" target="_blank">04-slurm_sapply.slurm</a>):</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=slurm_sapply
#SBATCH --time=01:00:00

module load usc r
Rscript --vanilla 04-slurm_sapply.R</code></pre>
<p>One of the main benefits of using this approach instead of the the <code>makeSlurmCluster</code> function (and thus, working with a SOCK cluster) are:</p>
<ul>
<li><p>The number of jobs is not limited here (only by the admin, but not by R).</p></li>
<li><p>If a job fails, then we can re-run it using <code>sbatch</code> once again (see example <a href="https://github.com/USCbiostats/slurmR#example-2-job-resubmission" target="_blank">here</a>).</p></li>
<li><p>You can check the individual logs of each process using the function <code>Slurm_lob()</code>.</p></li>
<li><p>You can submit the job and quick the R session without waiting for it to finalize. You can always read back the job using the function <code>read_slurm_job([path-to-the-temp])</code></p></li>
</ul>
</div>
<div id="case-5-skipping-the-.slurm-file" class="section level3">
<h3>Case 5: Skipping the .slurm file</h3>
<p>The <code>slurmR</code> package has a function named <code>sourceSlurm</code> that can be used to avoid creating the <code>.slurm</code> file. The user can add the SBATCH options to the top of the R script (including the <code>#!/bin/sh</code> line) and submit the job from within R as follows:</p>
<p>R script (<a href="05-sapply.R" target="_blank">05-sapply.R</a>):</p>
<pre><code>#!/bin/sh
#SBATCH --job-name=sapply-sourceSlurm
#SBATCH --time=01:00:00

# Model parameters
nsims &lt;- 1e3
n     &lt;- 1e4

# Function to simulate pi
simpi &lt;- function(i) {
  
  p &lt;- matrix(runif(n*2, -1, 1), ncol = 2)
  mean(sqrt(rowSums(p^2)) &lt;= 1) * 4
  
}

# Approximation
set.seed(12322)
ans &lt;- sapply(1:nsims, simpi)

saveRDS(ans, &quot;05-sapply.rds&quot;)</code></pre>
<p>From the R console (is OK if you are in the Head node)</p>
<pre class="r"><code>slurmR::sourceSlurm(&quot;05-sapply.R&quot;)</code></pre>
<p>And voilá! A temporary bash file will be generated and used submit the R script to the queue.</p>
</div>
</div>


</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
